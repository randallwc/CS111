NAME: William Randall
EMAIL: wrandall1000@gmail.com
ID: 805167986

Files:

lab2_add.c
//c source file for part 1 of lab2
SortedList.h
//header file for SortedList
SortedList.c
//c implementation file for SortedList.h
lab2_list.c
//c source file for part 2 of lab2

add_test.sh
list_test.sh
//shell script to test lab2_add and lab2_list

lab2_add.gp
lab2_list.gp
//gnuplot scripts

Makefile
//a make file

lab2_add.csv
lab2_list.csv
//comma separated values files for the graphs

lab2_add-1.png
lab2_add-2.png
lab2_add-3.png
lab2_add-4.png
lab2_add-5.png
//graphs for lab2_add

lab2_list-1.png
lab2_list-2.png
lab2_list-3.png
lab2_list-4.png
//graphs for lab2_list

README
//This file which describes the other files and answers the questions

Answers to Questions:
1 - QUESTION 2.1.1 - causing conflicts:
	1.1 - Why does it take many iterations before errors are seen?

	It takes many iterations because if there are few iterations there is a smaller chance that a thread will yiled during a 
	critical secion.  This means that the threads re more likely to run until complete.

	1.2 - Why does a significantly smaller number of iterations so seldom fail?

	When there are more iterations, the chance a thread will be forced to yield during a critical secion is much higher and
	yielding during a critical section is what causes an error which makes the program fail.

2 - QUESTION 2.1.2 - cost of yielding:
	2.1 - Why are the --yield runs so much slower?

	They are so much slower because the Operating System has to make a context switch for every yield, and this has a high cost.

	2.2 - Where is the additional time going?

	The additional time is going to when the program has to trap into the kernel, then save the stack of the current thread, then 
	load the stack of the new thread, and other processes which happen when the context switch happens.

	2.3 - Is it possible to get valid per-operation timings if we are using the --yield option?
	2.4 - If so, explain how. If not, explain why not.

	It is not possible because you cannot take the time it takes for the context switch from the time used for performing the current operation.

3 - QUESTION 2.1.3 - measurement errors:
	3.1 - Why does the average cost per operation drop with increasing iterations?

	The average cost per operation drops with more iterations because the overhead of making threads and performing context switches between
	the threads is big, but when you have more iterations there is the same overheadbut they are smaller in comparioson to the ammount 
	of operations completed.  Therefore, the per operation cost drops.

	3.2 - If the cost per iteration is a function of the number of iterations, how do we know how many iterations to run (or what the "correct" cost is)?

	If we run many iterations then the thread overhead will be small when compared to the time it takes for the operation, and this 
	will allow us to get a better picture of the operation cost.

4 - QUESTION 2.1.4 - costs of serialization:
	4.1 - Why do all of the options perform similarly for low numbers of threads?

	They all perform similarly for low number of threads because they have a lower chance to compete over shared resources. 
	The threads will be blocked less often when they are waiting for a locked resource which is locked by a different thread.
	The optons perform similarly because the cost of the lock does no affect the performance much.

	4.2 - Why do the three protected operations slow down as the number of threads rises?

	Threads have a higher chance to compete over shared resources when the number of threads is high, and this makes them 
	wait until the locked resources are free more often, which slows down operations.

5 - QUESTION 2.2.1 - scalability of Mutex
	5.1 - Compare the variation in time per mutex-protected operation vs the number of threads in Part-1 (adds) and Part-2 (sorted lists).
	5.2 - Comment on the general shapes of the curves, and explain why they have this shape.
	5.3 - Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.

	The curve for adds increases linearly then becomes flat.
	The curve for lists increases linearly, and this might be because the critical section for lists is bigger so the time spent waiting is higher.

6 - QUESTION 2.2.2 - scalability of spin locks
	6.1 - Compare the variation in time per protected operation vs the number of threads for list operations protected by Mutex vs Spin locks.
	6.2 - Comment on the general shapes of the curves, and explain why they have this shape.
	6.3 - Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.

	The rate of the increase doesn't look like it varys between the type of lock, and the curve for mutex and spin's add and list seems to be similar.
	For add the curve flattens out but for list it increases linearly as the number of threads increases.
	For add the cost of the mutex and spin locks are almost the same, where the most efficient are compare and swap.
	The reason spin is efficient is because it is simple and has a small overhead, but as the threads increase, the overhead of the mutex lock
	becomes a large part of the time and this makes the performance become much worse when compared to a spin lock.

Links to sources:
https://man7.org/linux/man-pages/man7/pthreads.7.html
https://man7.org/linux/man-pages/man2/clock_gettime.2.html
https://www.geeksforgeeks.org/multithreading-in-operating-system/
https://www.geeksforgeeks.org/multithreading-c-2/